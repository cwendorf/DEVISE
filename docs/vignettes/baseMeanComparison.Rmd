---
title: "Mean Comparisons with Base R"
output:
  github_document:
    preserve_yaml: FALSE
vignette: >
  %\VignetteIndexEntry{Mean Comparisons with Base R}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include=FALSE}
knitr::opts_chunk$set(comment = NA)
devtools::source_gist("8e6e5dc401e3fc1042ef7a030f9d19c7", filename = "revised_toc.R")
```

## Mean Comparisons with Base R

This vignette walks through a complete mean comparison workflow using Base R for data entry and DEVISE for interval extraction and visualization. Each step builds on the previous one, ending with a comparison table and plot.

```{r toc, echo=FALSE}
knitr::current_input() -> thisfile
revised_toc(thisfile, base_level = 3, toc_depth = 4)
```

---

### Load the Packages

```{r, include=FALSE}
if (!require(remotes)) install.packages("remotes")
if (!require(DEVISE)) {remotes::install_github("cwendorf/DEVISE")}
library(DEVISE)
```

### Case 1: Raw Data Input

#### Input the Data

Create a simple factor and outcome vector that will be used to compute condition-specific statistics.

```{r}
gl(3, 10, labels = c("Level1", "Level2", "Level3")) -> Factor
c(6, 8, 6, 8, 10, 8, 10, 9, 8, 7, 7, 13, 11, 10, 13, 8, 11, 14, 12, 11, 9, 16, 11, 12, 15, 13, 9, 14, 11, 10) -> Outcome
```

#### Examine the Conditions

Compute confidence intervals for each level and assemble them into a conditions matrix.

```{r}
Outcome[Factor == "Level1"] |> t.test() |> extract_intervals() -> Level1
Outcome[Factor == "Level2"] |> t.test() |> extract_intervals() -> Level2
Outcome[Factor == "Level3"] |> t.test() |> extract_intervals() -> Level3

rbind(Level1, Level2, Level3) -> Conditions
c("Level1", "Level2", "Level3") -> rownames(Conditions)
```

#### Display the Conditions

Format the conditions matrix and visualize the confidence intervals.

```{r}
Conditions |> style_matrix(title = "Table 1: Means and Confidence Intervals", style = "apa")
Conditions |> plot_conditions(title = "Figure 1: Conditions Confidence Intervals", values = TRUE)
```

#### Make a Comparison

Subset the data to the two conditions that will be compared directly.

```{r}
Outcome[Factor %in% c("Level1", "Level2")] -> Outcome_Sub
Factor[Factor %in% c("Level1", "Level2")] -> Factor_Sub
```

#### Examine a Comparison

Compute the comparison interval between the two selected conditions.

```{r}
(Outcome_Sub ~ Factor_Sub) |> t.test() |> extract_intervals() -> Difference

rbind(Level1, Level2, Difference) -> Comparison
c("Level1", "Level2", "Difference") -> rownames(Comparison)
```

#### Display a Comparison

Present the comparison in a formatted table and plot.

```{r}
Comparison |> style_matrix(title = "Table 2: Means, Confidence Intervals, and Comparison", style = "apa")
Comparison |> plot_comparison(title = "Figure 2: Comparison Confidence Intervals", values = TRUE)
```
